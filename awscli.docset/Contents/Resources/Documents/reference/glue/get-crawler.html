<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
    
  
    <title>get-crawler — AWS CLI 1.16.309 Command Reference</title>
  <link rel="stylesheet" type="text/css" href="../../_static/bootstrap.min.css">
  <script type="text/javascript" src="../../_static/jquery-1.9.1.min.js"></script>
  <script src="/SdkStatic/sdk-priv.js" async="true"></script>
    
    <link rel="stylesheet" href="../../_static/guzzle.css" type="text/css">
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css">
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../../',
        VERSION:     '1.16.309',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="../../_static/jquery.js"></script>
    <script type="text/javascript" src="../../_static/underscore.js"></script>
    <script type="text/javascript" src="../../_static/doctools.js"></script>
    <link rel="top" title="AWS CLI 1.16.309 Command Reference" href="../../index.html">
    <link rel="up" title="glue" href="index.html">
    <link rel="next" title="get-crawler-metrics" href="get-crawler-metrics.html">
    <link rel="prev" title="get-connections" href="get-connections.html">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <link rel="stylesheet" type="text/css" href="../../_static/bootstrap-responsive.min.css">
  
   

  </head>
  <body>
  
  
  <!--REGION_DISCLAIMER_DO_NOT_REMOVE-->

    
    <div class="container">
        
    
  
        <div class="document clearer">
      
            <div class="body">
              
  
<div class="section" id="get-crawler">
<span id="cli-aws-glue-get-crawler"></span><h1>get-crawler<a class="headerlink" href="#get-crawler" title="Permalink to this headline">¶</a>
</h1>
<div class="section" id="description">
<h2>Description<a class="headerlink" href="#description" title="Permalink to this headline">¶</a>
</h2>
<p>Retrieves metadata for a specified crawler.</p>
<p>See also: <a class="reference external" href="https://docs.aws.amazon.com/goto/WebAPI/glue-2017-03-31/GetCrawler">AWS API Documentation</a></p>
<p>See <a class="reference internal" href="../index.html"><em>'aws help'</em></a> for descriptions of global parameters.</p>
</div>
<div class="section" id="synopsis">
<h2>Synopsis<a class="headerlink" href="#synopsis" title="Permalink to this headline">¶</a>
</h2>
<div class="highlight-python">
<pre>  get-crawler
--name &lt;value&gt;
[--cli-input-json &lt;value&gt;]
[--generate-cli-skeleton &lt;value&gt;]</pre>
</div>
</div>
<div class="section" id="options">
<h2>Options<a class="headerlink" href="#options" title="Permalink to this headline">¶</a>
</h2>
<p><tt class="docutils literal"><span class="pre">--name</span></tt> (string)</p>
<blockquote>
<div>The name of the crawler to retrieve metadata for.</div>
</blockquote>
<p><tt class="docutils literal"><span class="pre">--cli-input-json</span></tt> (string)
Performs service operation based on the JSON string provided. The JSON string follows the format provided by <tt class="docutils literal"><span class="pre">--generate-cli-skeleton</span></tt>. If other arguments are provided on the command line, the CLI values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally.</p>
<p><tt class="docutils literal"><span class="pre">--generate-cli-skeleton</span></tt> (string)
Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value <tt class="docutils literal"><span class="pre">input</span></tt>, prints a sample input JSON that can be used as an argument for <tt class="docutils literal"><span class="pre">--cli-input-json</span></tt>. If provided with the value <tt class="docutils literal"><span class="pre">output</span></tt>, it validates the command inputs and returns a sample output JSON for that command.</p>
<p>See <a class="reference internal" href="../index.html"><em>'aws help'</em></a> for descriptions of global parameters.</p>
</div>
<div class="section" id="output">
<h2>Output<a class="headerlink" href="#output" title="Permalink to this headline">¶</a>
</h2>
<p>Crawler -&gt; (structure)</p>
<blockquote>
<div>
<p>The metadata for the specified crawler.</p>
<p>Name -&gt; (string)</p>
<blockquote>
<div>The name of the crawler.</div>
</blockquote>
<p>Role -&gt; (string)</p>
<blockquote>
<div>The Amazon Resource Name (ARN) of an IAM role that's used to access customer resources, such as Amazon Simple Storage Service (Amazon S3) data.</div>
</blockquote>
<p>Targets -&gt; (structure)</p>
<blockquote>
<div>
<p>A collection of targets to crawl.</p>
<p>S3Targets -&gt; (list)</p>
<blockquote>
<div>
<p>Specifies Amazon Simple Storage Service (Amazon S3) targets.</p>
<p>(structure)</p>
<blockquote>
<div>
<p>Specifies a data store in Amazon Simple Storage Service (Amazon S3).</p>
<p>Path -&gt; (string)</p>
<blockquote>
<div>The path to the Amazon S3 target.</div>
</blockquote>
<p>Exclusions -&gt; (list)</p>
<blockquote>
<div>
<p>A list of glob patterns used to exclude from the crawl. For more information, see <a class="reference external" href="http://docs.aws.amazon.com/glue/latest/dg/add-crawler.html">Catalog Tables with a Crawler</a> .</p>
<p>(string)</p>
</div>
</blockquote>
</div>
</blockquote>
</div>
</blockquote>
<p>JdbcTargets -&gt; (list)</p>
<blockquote>
<div>
<p>Specifies JDBC targets.</p>
<p>(structure)</p>
<blockquote>
<div>
<p>Specifies a JDBC data store to crawl.</p>
<p>ConnectionName -&gt; (string)</p>
<blockquote>
<div>The name of the connection to use to connect to the JDBC target.</div>
</blockquote>
<p>Path -&gt; (string)</p>
<blockquote>
<div>The path of the JDBC target.</div>
</blockquote>
<p>Exclusions -&gt; (list)</p>
<blockquote>
<div>
<p>A list of glob patterns used to exclude from the crawl. For more information, see <a class="reference external" href="http://docs.aws.amazon.com/glue/latest/dg/add-crawler.html">Catalog Tables with a Crawler</a> .</p>
<p>(string)</p>
</div>
</blockquote>
</div>
</blockquote>
</div>
</blockquote>
<p>DynamoDBTargets -&gt; (list)</p>
<blockquote>
<div>
<p>Specifies Amazon DynamoDB targets.</p>
<p>(structure)</p>
<blockquote>
<div>
<p>Specifies an Amazon DynamoDB table to crawl.</p>
<p>Path -&gt; (string)</p>
<blockquote>
<div>The name of the DynamoDB table to crawl.</div>
</blockquote>
</div>
</blockquote>
</div>
</blockquote>
<p>CatalogTargets -&gt; (list)</p>
<blockquote>
<div>
<p>Specifies AWS Glue Data Catalog targets.</p>
<p>(structure)</p>
<blockquote>
<div>
<p>Specifies an AWS Glue Data Catalog target.</p>
<p>DatabaseName -&gt; (string)</p>
<blockquote>
<div>The name of the database to be synchronized.</div>
</blockquote>
<p>Tables -&gt; (list)</p>
<blockquote>
<div>
<p>A list of the tables to be synchronized.</p>
<p>(string)</p>
</div>
</blockquote>
</div>
</blockquote>
</div>
</blockquote>
</div>
</blockquote>
<p>DatabaseName -&gt; (string)</p>
<blockquote>
<div>The name of the database in which the crawler's output is stored.</div>
</blockquote>
<p>Description -&gt; (string)</p>
<blockquote>
<div>A description of the crawler.</div>
</blockquote>
<p>Classifiers -&gt; (list)</p>
<blockquote>
<div>
<p>A list of UTF-8 strings that specify the custom classifiers that are associated with the crawler.</p>
<p>(string)</p>
</div>
</blockquote>
<p>SchemaChangePolicy -&gt; (structure)</p>
<blockquote>
<div>
<p>The policy that specifies update and delete behaviors for the crawler.</p>
<p>UpdateBehavior -&gt; (string)</p>
<blockquote>
<div>The update behavior when the crawler finds a changed schema.</div>
</blockquote>
<p>DeleteBehavior -&gt; (string)</p>
<blockquote>
<div>The deletion behavior when the crawler finds a deleted object.</div>
</blockquote>
</div>
</blockquote>
<p>State -&gt; (string)</p>
<blockquote>
<div>Indicates whether the crawler is running, or whether a run is pending.</div>
</blockquote>
<p>TablePrefix -&gt; (string)</p>
<blockquote>
<div>The prefix added to the names of tables that are created.</div>
</blockquote>
<p>Schedule -&gt; (structure)</p>
<blockquote>
<div>
<p>For scheduled crawlers, the schedule when the crawler runs.</p>
<p>ScheduleExpression -&gt; (string)</p>
<blockquote>
<div>A <tt class="docutils literal"><span class="pre">cron</span></tt> expression used to specify the schedule. For more information, see <a class="reference external" href="http://docs.aws.amazon.com/glue/latest/dg/monitor-data-warehouse-schedule.html">Time-Based Schedules for Jobs and Crawlers</a> . For example, to run something every day at 12:15 UTC, specify <tt class="docutils literal"><span class="pre">cron(15</span> <span class="pre">12</span> <span class="pre">*</span> <span class="pre">*</span> <span class="pre">?</span> <span class="pre">*)</span></tt> .</div>
</blockquote>
<p>State -&gt; (string)</p>
<blockquote>
<div>The state of the schedule.</div>
</blockquote>
</div>
</blockquote>
<p>CrawlElapsedTime -&gt; (long)</p>
<blockquote>
<div>If the crawler is running, contains the total time elapsed since the last crawl began.</div>
</blockquote>
<p>CreationTime -&gt; (timestamp)</p>
<blockquote>
<div>The time that the crawler was created.</div>
</blockquote>
<p>LastUpdated -&gt; (timestamp)</p>
<blockquote>
<div>The time that the crawler was last updated.</div>
</blockquote>
<p>LastCrawl -&gt; (structure)</p>
<blockquote>
<div>
<p>The status of the last crawl, and potentially error information if an error occurred.</p>
<p>Status -&gt; (string)</p>
<blockquote>
<div>Status of the last crawl.</div>
</blockquote>
<p>ErrorMessage -&gt; (string)</p>
<blockquote>
<div>If an error occurred, the error information about the last crawl.</div>
</blockquote>
<p>LogGroup -&gt; (string)</p>
<blockquote>
<div>The log group for the last crawl.</div>
</blockquote>
<p>LogStream -&gt; (string)</p>
<blockquote>
<div>The log stream for the last crawl.</div>
</blockquote>
<p>MessagePrefix -&gt; (string)</p>
<blockquote>
<div>The prefix for a message about this crawl.</div>
</blockquote>
<p>StartTime -&gt; (timestamp)</p>
<blockquote>
<div>The time at which the crawl started.</div>
</blockquote>
</div>
</blockquote>
<p>Version -&gt; (long)</p>
<blockquote>
<div>The version of the crawler.</div>
</blockquote>
<p>Configuration -&gt; (string)</p>
<blockquote>
<div>Crawler configuration information. This versioned JSON string allows users to specify aspects of a crawler's behavior. For more information, see <a class="reference external" href="http://docs.aws.amazon.com/glue/latest/dg/crawler-configuration.html">Configuring a Crawler</a> .</div>
</blockquote>
<p>CrawlerSecurityConfiguration -&gt; (string)</p>
<blockquote>
<div>The name of the <tt class="docutils literal"><span class="pre">SecurityConfiguration</span></tt> structure to be used by this crawler.</div>
</blockquote>
</div>
</blockquote>
</div>
</div>


            </div>
          <div class="clearfix"></div>
        </div>
        
    
  

    </div>
  <script type="text/javascript" src="https://media.amazonwebservices.com/js/sitecatalyst/s_code.min.js"></script>
  <script type="text/javascript">
  s.prop66 = 'AWS CLI';
  s.eVar66 = 'D=c66';
  s.prop65 = 'API Reference';
  s.eVar65 = 'D=c65';
  var s_code = s.t();
  if (s_code) document.write(s_code);
  </script>
    
  



  
    
  
  </body>
</html>
